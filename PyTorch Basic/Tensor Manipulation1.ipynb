{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /Users/dan_bibibi/opt/anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - pytorch\n",
      "    - torchvision\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    conda-4.10.3               |   py38hecd8cb5_0         2.9 MB\n",
      "    libuv-1.40.0               |       haf1e3a3_0         334 KB\n",
      "    ninja-1.10.2               |       hf7b0b51_1         106 KB\n",
      "    pytorch-1.7.1              |          py3.8_0        64.5 MB  pytorch\n",
      "    torchvision-0.8.2          |         py38_cpu         6.5 MB  pytorch\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        74.4 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  libuv              pkgs/main/osx-64::libuv-1.40.0-haf1e3a3_0\n",
      "  ninja              pkgs/main/osx-64::ninja-1.10.2-hf7b0b51_1\n",
      "  pytorch            pytorch/osx-64::pytorch-1.7.1-py3.8_0\n",
      "  torchvision        pytorch/osx-64::torchvision-0.8.2-py38_cpu\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  conda                                4.9.2-py38hecd8cb5_0 --> 4.10.3-py38hecd8cb5_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "torchvision-0.8.2    | 6.5 MB    | ##################################### | 100% \n",
      "ninja-1.10.2         | 106 KB    | ##################################### | 100% \n",
      "libuv-1.40.0         | 334 KB    | ##################################### | 100% \n",
      "pytorch-1.7.1        | 64.5 MB   | ##################################### | 100% \n",
      "conda-4.10.3         | 2.9 MB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install pytorch torchvision -c pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D tensor : (batch size, width, height) - img / (batch size, length, dim) - nlp\n",
    "import numpy as np \n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 2. 3. 4. 5. 6.]\n",
      "Rank of t : 1\n",
      "Shape of t : (7,)\n",
      "t[0] t[1] t[-1] =  0.0 1.0 6.0\n",
      "t[2:5] t[4:-1]  =  [2. 3. 4.] [4. 5.]\n",
      "t[:2] t[3:]     =  [0. 1.] [3. 4. 5. 6.]\n"
     ]
    }
   ],
   "source": [
    "# 1D with Numpy\n",
    "t = np.array([0., 1., 2., 3., 4., 5., 6.])\n",
    "\n",
    "print(t)\n",
    "print('Rank of t :',t.ndim)\n",
    "print('Shape of t :', t.shape)\n",
    "print('t[0] t[1] t[-1] = ', t[0], t[1], t[-1]) # 인덱스를 통한 원소 접근\n",
    "print('t[2:5] t[4:-1]  = ', t[2:5], t[4:-1]) # 범위 지정 (끝 번호 전까지)\n",
    "print('t[:2] t[3:]     = ', t[:2], t[3:]) # 처음~번호 전, 번호~끝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  2.  3.]\n",
      " [ 4.  5.  6.]\n",
      " [ 7.  8.  9.]\n",
      " [10. 11. 12.]]\n",
      "Rank  of t:  2\n",
      "Shape of t:  (4, 3)\n"
     ]
    }
   ],
   "source": [
    "# 2D with Numpy\n",
    "t = np.array([[1., 2., 3.], [4., 5., 6.], [7., 8., 9.], [10., 11., 12.]])\n",
    "\n",
    "print(t)\n",
    "print('Rank  of t: ', t.ndim)\n",
    "print('Shape of t: ', t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 2., 3., 4., 5., 6.])\n",
      "1\n",
      "torch.Size([7])\n",
      "torch.Size([7])\n",
      "tensor(0.) tensor(1.) tensor(6.)\n",
      "tensor([2., 3., 4.]) tensor([4., 5.])\n",
      "tensor([0., 1.]) tensor([3., 4., 5., 6.])\n"
     ]
    }
   ],
   "source": [
    "# 1D with PyTorch\n",
    "t = torch.FloatTensor([0., 1., 2., 3., 4., 5., 6.])\n",
    "\n",
    "print(t)\n",
    "print(t.dim())  # rank. 즉, 차원\n",
    "print(t.shape)  # shape\n",
    "print(t.size()) # shape\n",
    "print(t[0], t[1], t[-1])  # 인덱스로 접근\n",
    "print(t[2:5], t[4:-1])    # 슬라이싱\n",
    "print(t[:2], t[3:])       # 슬라이싱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.],\n",
      "        [ 7.,  8.,  9.],\n",
      "        [10., 11., 12.]])\n",
      "2\n",
      "torch.Size([4, 3])\n",
      "tensor([ 2.,  5.,  8., 11.])\n",
      "torch.Size([4])\n",
      "tensor([[ 1.,  2.],\n",
      "        [ 4.,  5.],\n",
      "        [ 7.,  8.],\n",
      "        [10., 11.]])\n"
     ]
    }
   ],
   "source": [
    "# 2D with PyTorch\n",
    "t = torch.FloatTensor([[1., 2., 3.],\n",
    "                       [4., 5., 6.],\n",
    "                       [7., 8., 9.],\n",
    "                       [10., 11., 12.]\n",
    "                      ])\n",
    "\n",
    "print(t)\n",
    "print(t.dim())  # rank. 즉, 차원\n",
    "print(t.size()) # shape\n",
    "print(t[:, 1]) # 첫번째 차원을 전체 선택한 상황에서 두번째 차원의 첫번째 것만 가져옴\n",
    "print(t[:, 1].size()) # ↑ 위의 경우의 크기\n",
    "print(t[:, :-1]) # 첫번째 차원을 전체 선택한 상황에서 두번째 차원에서는 맨 마지막에서 첫번째를 제외하고 다 가져옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5., 5.]])\n",
      "\n",
      "tensor([[4., 5.]])\n",
      "\n",
      "tensor([[4., 5.],\n",
      "        [5., 6.]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Broadcasting (자동으로 크기를 맞춰서 연산을 수행)\n",
    "\n",
    "m1 = torch.FloatTensor([[3, 3]])\n",
    "m2 = torch.FloatTensor([[2, 2]])\n",
    "print(m1 + m2)\n",
    "print()\n",
    "\n",
    "# Vector + scalar\n",
    "m1 = torch.FloatTensor([[1, 2]])\n",
    "m2 = torch.FloatTensor([3]) # [3] -> [3, 3]\n",
    "print(m1 + m2)\n",
    "print()\n",
    "\n",
    "# 2 x 1 Vector + 1 x 2 Vector\n",
    "m1 = torch.FloatTensor([[1, 2]])\n",
    "m2 = torch.FloatTensor([[3], [4]])\n",
    "print(m1 + m2)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Matrix 1:  torch.Size([2, 2])\n",
      "Shape of Matrix 2:  torch.Size([2, 1])\n",
      "tensor([[ 5.],\n",
      "        [11.]])\n",
      "\n",
      "Shape of Matrix 1:  torch.Size([2, 2])\n",
      "Shape of Matrix 2:  torch.Size([2, 1])\n",
      "tensor([[1., 2.],\n",
      "        [6., 8.]])\n",
      "tensor([[1., 2.],\n",
      "        [6., 8.]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 행렬 곱셈\n",
    "m1 = torch.FloatTensor([[1, 2], [3, 4]])\n",
    "m2 = torch.FloatTensor([[1], [2]])\n",
    "print('Shape of Matrix 1: ', m1.shape) # 2 x 2\n",
    "print('Shape of Matrix 2: ', m2.shape) # 2 x 1\n",
    "print(m1.matmul(m2)) # 2 x 1\n",
    "print()\n",
    "\n",
    "# element-wise 곱셈\n",
    "m1 = torch.FloatTensor([[1, 2], [3, 4]])\n",
    "m2 = torch.FloatTensor([[1], [2]])\n",
    "print('Shape of Matrix 1: ', m1.shape) # 2 x 2\n",
    "print('Shape of Matrix 2: ', m2.shape) # 2 x 1\n",
    "print(m1 * m2) # 2 x 2\n",
    "print(m1.mul(m2))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.5000)\n",
      "\n",
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "tensor(2.5000)\n",
      "tensor([2., 3.])\n",
      "tensor([1.5000, 3.5000])\n"
     ]
    }
   ],
   "source": [
    "# Mean \n",
    "t = torch.FloatTensor([1, 2])\n",
    "print(t.mean())\n",
    "print()\n",
    "\n",
    "t = torch.FloatTensor([[1, 2], [3, 4]])\n",
    "print(t)\n",
    "print(t.mean())\n",
    "print(t.mean(dim=0)) # dim=0 : 첫번째 차원(행) 제거, 즉 '열'만 남기겠다는 의미 (2, 2) -> (1, 2)\n",
    "print(t.mean(dim=1)) # 열이 제거된 tensor (2, 2) -> (2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "tensor(10.)\n",
      "tensor([4., 6.])\n",
      "tensor([3., 7.])\n",
      "tensor([3., 7.])\n"
     ]
    }
   ],
   "source": [
    "# Sum\n",
    "t = torch.FloatTensor([[1, 2], [3, 4]])\n",
    "print(t)\n",
    "\n",
    "print(t.sum()) # 단순히 원소 전체의 덧셈을 수행\n",
    "print(t.sum(dim=0)) # 행을 제거\n",
    "print(t.sum(dim=1)) # 열을 제거\n",
    "print(t.sum(dim=-1)) # 열을 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "tensor(4.)\n",
      "torch.return_types.max(\n",
      "values=tensor([3., 4.]),\n",
      "indices=tensor([1, 1]))\n",
      "\n",
      "Max:  tensor([3., 4.])\n",
      "Argmax:  tensor([1, 1])\n",
      "\n",
      "torch.return_types.max(\n",
      "values=tensor([2., 4.]),\n",
      "indices=tensor([1, 1]))\n",
      "torch.return_types.max(\n",
      "values=tensor([2., 4.]),\n",
      "indices=tensor([1, 1]))\n"
     ]
    }
   ],
   "source": [
    "# Max, ArgMax\n",
    "t = torch.FloatTensor([[1, 2], [3, 4]])\n",
    "print(t)\n",
    "\n",
    "print(t.max()) # Returns one value: max\n",
    "print(t.max(dim=0)) # Returns two values: max and argmax(최대값을 가진 인덱스)\n",
    "print()\n",
    "\n",
    "print('Max: ', t.max(dim=0)[0])\n",
    "print('Argmax: ', t.max(dim=0)[1])\n",
    "print()\n",
    "\n",
    "print(t.max(dim=1))\n",
    "print(t.max(dim=-1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
